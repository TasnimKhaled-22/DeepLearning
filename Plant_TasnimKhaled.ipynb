{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Hpw0KPTu2AZM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Dense, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D, Activation, BatchNormalization, Dropout)\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import (ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler, CSVLogger, LambdaCallback)\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n",
        "# Additional imports for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARJp16TN2ZXS",
        "outputId": "92c0d8ff-99f9-4634-e77a-08a9017ff09c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Path\n",
        "train_path = '/content/drive/MyDrive/Train'\n",
        "test_path = '/content/drive/MyDrive/Test'"
      ],
      "metadata": {
        "id": "_fFa8bmd27bL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob ('/content/drive/MyDrive/Train/*')\n",
        "print(len(folders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEo_-d_C3n5q",
        "outputId": "6445ea2e-2719-4060-af61-b5bae74498f2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image size and number of classes\n",
        "img_size = (256, 256)\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "xsKhaljBCtXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model from the pre-trained model vgg16\n",
        "\n",
        "model_vgg16 = VGG16(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))\n",
        "model = Sequential()\n",
        "\n",
        "for layer in model_vgg16.layers:\n",
        "  model.add(layer)\n",
        "\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False # Not trainable weights\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wut8duko6eNn",
        "outputId": "cb7d8388-8264-4908-9b48-02998c7a749d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " flatten_106 (Flatten)       (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 512)               16777728  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31760202 (121.16 MB)\n",
            "Trainable params: 17045514 (65.02 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "img_size = 256\n",
        "for i in os.listdir('/content/drive/MyDrive/Test'):\n",
        "    files = glob.glob(pathname=str(os.path.join('/content/drive/MyDrive/Test', i, '*.jpg')))\n",
        "\n",
        "    for j in tqdm(files):  # Use tqdm as a function\n",
        "        # Process each JPEG file\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tx62o1HQlOQ",
        "outputId": "afbeea05-f83a-4509-b6ab-c014c841d590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 93902.33it/s]\n",
            "100%|██████████| 12/12 [00:00<00:00, 213269.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "i5aSAc8l5cRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Example configuration, you can modify this based on your requirements\n",
        "data_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Now you can use data_datagen in your flow_from_directory method\n",
        "train_set = data_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Train',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='binary',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk95yVVfAGxZ",
        "outputId": "36c40845-6851-4e50-f299-d5f35b3bf1c5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 104 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Example configuration for test data augmentation (you can modify based on your needs)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Now you can use test_datagen in your flow_from_directory method\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Test',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='binary',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYqSJ9vs9PqC",
        "outputId": "350369c4-349a-4120-b71d-4f1df3ac9694"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm  # If you haven't imported tqdm already\n",
        "\n",
        "batch_size = 64  # Adjust the batch size based on your needs\n",
        "\n",
        "train_generator.reset()\n",
        "X_train, y_train = next(train_generator)\n",
        "\n",
        "for i in tqdm.tqdm(range(int(train_generator.n/batch_size)-1)):\n",
        "    img, label = next(train_generator)\n",
        "    X_train = np.append(X_train, img, axis=0)\n",
        "    y_train = np.append(y_train, label, axis=0)\n",
        "print(X_train.shape, y_train.shape)\n",
        "    # Your additional code inside the loop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQtVCIfT2hHg",
        "outputId": "b366f979-b224-419c-f295-13244de3f494"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 256, 256, 3) (64,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = next(test_set)\n",
        "for i in tqdm.tqdm(range(int(train_generator.n/batch_size)-1)):\n",
        "  img, label = next(train_generator)\n",
        "  X_train = np.append(X_train, img, axis=0 )\n",
        "  y_train = np.append(y_train, label, axis=0)\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSyjqhjq3jZm",
        "outputId": "f358607a-2284-4e6a-a607-22aadd778149"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 256, 256, 3) (64,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an ImageDataGenerator with desired augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Function to apply augmentation twice to each dataset\n",
        "def augment_dataset(dataset):\n",
        "    augmented_data = []\n",
        "    for img in dataset:\n",
        "        img = np.expand_dims(img, axis=0)  # Expanding dimensions for batch size\n",
        "        for _ in range(1):  # Apply augmentation twice\n",
        "            for batch in datagen.flow(img, batch_size=1):\n",
        "                augmented_data.append(np.squeeze(batch))  # Remove the batch dimension\n",
        "                break  # Stop the loop after one augmented image\n",
        "    return np.array(augmented_data)"
      ],
      "metadata": {
        "id": "NsFyZVQ73yxC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "metrics = [\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.AUC(),\n",
        "        tf.keras.metrics.Recall(),\n",
        "        tf.keras.metrics.Precision(),\n",
        "        tf.keras.metrics.F1Score(),\n",
        "        tf.keras.metrics.SpecificityAtSensitivity(0.5),\n",
        "        tf.keras.metrics.SensitivityAtSpecificity(0.5),\n",
        "        tf.keras.metrics.FalseNegatives(),\n",
        "        tf.keras.metrics.FalsePositives(),\n",
        "        tf.keras.metrics.TrueNegatives(),\n",
        "        tf.keras.metrics.TruePositives(),]"
      ],
      "metadata": {
        "id": "ogjNRAAw4LjS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.1), loss = 'binary_crossentropy',metrics = metrics)"
      ],
      "metadata": {
        "id": "IOE7jBPG4S9J"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_train_combined is your binary labels\n",
        "y_train_combined = y_train_combined.reshape((-1, 1))"
      ],
      "metadata": {
        "id": "DIWn-3eZ5xPq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming num_classes is the number of classes in your problem\n",
        "num_classes = 2\n",
        "y_train_combined = to_categorical(y_train_combined, num_classes)"
      ],
      "metadata": {
        "id": "7KH_XaLy50Yz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# Add your layers here\n",
        "\n",
        "# For binary classification, use a single neuron with sigmoid activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with an appropriate optimizer, loss, and metrics\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5DQTEG_G8g0z"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_combined = y_train_combined.ravel()  # or y_train_combined = y_train_combined.flatten()"
      ],
      "metadata": {
        "id": "ZoG4-aCO8jYh"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "d243wRVF88cE"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# Add your layers here\n",
        "\n",
        "# For binary classification, use a single neuron with sigmoid activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with an appropriate optimizer, loss, and metrics\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CTJECNiL9Kwj"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_combined = y_train_combined.ravel()  # or y_train_combined = y_train_combined.flatten()"
      ],
      "metadata": {
        "id": "L4mVisaG9Mbr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G-hp2jsq9PDF"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# Add your layers here\n",
        "\n",
        "# For binary classification, use a single neuron with sigmoid activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with an appropriate optimizer, loss, and metrics\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vjn8Ifmp6LQs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_combined = y_train_combined.reshape((-1, 1))"
      ],
      "metadata": {
        "id": "LNrKWGIF6NGf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Train'\n",
        "\n",
        "img_size = 256\n",
        "for i in os.listdir(train_path):\n",
        "    files = glob(pathname=str(os.path.join(train_path, i, '*.jpg')))\n",
        "\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    for j in tqdm(files):\n",
        "        input_img = Input(shape=(256,256, 3))\n",
        "        x = Conv2D(16, (3, 3), activation='relu')(input_img)\n",
        "        x = MaxPooling2D((2, 2))(x)\n",
        "        x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "        x = MaxPooling2D((2, 2))(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(64, activation='relu')(x)\n",
        "        x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        inputs.append(input_img)\n",
        "        outputs.append(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ1TlGGfbEgv",
        "outputId": "c273dab0-1464-41d8-dca1-699edb015f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 52/52 [00:04<00:00, 10.81it/s]\n",
            "100%|██████████| 52/52 [00:06<00:00,  7.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# Add your layers here\n",
        "\n",
        "# For binary classification, use a single neuron with sigmoid activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with an appropriate optimizer, loss, and metrics\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "wS0iG9uTb2nA"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the output layer from the functional model\n",
        "output_layer = model_vgg16.output"
      ],
      "metadata": {
        "id": "nrbkXS8rcJg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Freeze the layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create your own model on top of the VGG16 base\n",
        "x = base_model.output\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "predictions = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS_NRfH-JVDS",
        "outputId": "98bee3f5-732c-480b-d0f4-6ca196243cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Assuming your previous model definition using the functional API\n",
        "# For example:\n",
        "inputs = Input(shape=(256,256,3))\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "# ... add more layers as needed\n",
        "\n",
        "# Output layer for binary classification with sigmoid activation\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Uii07PE7MVnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define your model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(256,256,3)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Now you can use model.fit_generator\n",
        "model_history = model.fit_generator(\n",
        "    train_set,\n",
        "    validation_data=test_set,\n",
        "    epochs=10\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "82mU8DAq_ybP",
        "outputId": "1c1992be-771c-4731-9d1f-369049b7b3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-85b7a239ebc8>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Now you can use model.fit_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m model_history = model.fit_generator(\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Model\n",
        "early_stopping_monitor = EarlyStopping(patience = 2)\n",
        "model.fit(x_train,y_train,validation_split = 0.3,epochs = 100,batch_size = 64, callbacks = [early_stopping_monitor])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "CsENG0KHR-p4",
        "outputId": "02f846ae-0a11-4ab1-f2ad-42f4041135a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-def839bfdc1b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mearly_stopping_monitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape=IMAGE_SIZE+[3],weights='imagenet',include_top=False)\n",
        "vgg.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4PecjFS3Ax1",
        "outputId": "d2e12abf-c6f5-4d99-e648-07e09529f8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 8, 8, 512) dtype=float32 (created by layer 'block5_pool')>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ]
}